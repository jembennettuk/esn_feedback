{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as gl\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib as mpl\n",
    "import myutils as mu\n",
    "import params_feedback as par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modName = 'FB2'\n",
    "expName = 'LocMin'\n",
    "dataName = 'out_accValTa'\n",
    "baseDirName = '/home/jb739/sheffield/proj/esn_feedback/data/'+modName+'_'+expName\n",
    "dirNames = gl.glob(baseDirName); dirNames.sort()\n",
    "# complete = torch.load('/home/jb739/sheffield/proj/esn_feedback/data/'+modName+'_'+expName+'/complete.pt') \n",
    "# nLR = complete.shape[0]\n",
    "data = []; nRuns = []\n",
    "for j,dirName in enumerate(dirNames): # loop over learning rates\n",
    "    # runs = complete[j,:]>0 # Boolean vector of which runs completed\n",
    "    # nRuns.append(np.sum(runs.long().numpy())) # Number of completed runs\n",
    "    data.append([])\n",
    "    # if nRuns[j]>0:  # If there are any runs, do:\n",
    "    fileNames = gl.glob(dirName+'/'+dataName+'*'); fileNames.sort()\n",
    "    for k, fileName in enumerate(fileNames): # loop over runs (random seeds)\n",
    "        data[j].append(torch.load(fileName))\n",
    "\n",
    "modName = 'FB2'\n",
    "expName = 'swLR'\n",
    "dataName = 'out_accValTa'\n",
    "baseDirName = '/home/jb739/sheffield/proj/esn_feedback/data/'+modName+'_'+expName\n",
    "dirNames = gl.glob(baseDirName+'_*'); dirNames.sort()\n",
    "complete = torch.load('/home/jb739/sheffield/proj/esn_feedback/data/'+modName+'_'+expName+'_0/complete.pt') \n",
    "nLR = complete.shape[0]\n",
    "datam = []; nRuns = []\n",
    "j = 4; dirName = dirNames[j]\n",
    "fileNames = gl.glob(dirName+'/'+dataName+'*'); fileNames.sort()\n",
    "temp = torch.load(fileNames[0])                \n",
    "datam.append(np.expand_dims(np.array(torch.load(fileNames[0])), axis=1))\n",
    "for k in range(1,len(fileNames)): # loop over runs (random seeds)\n",
    "    datam[0] = np.concatenate((datam[0], np.expand_dims(np.array(torch.load(fileNames[k])), axis=1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.setupMatplotlib()\n",
    "kernel = np.ones(50)/50\n",
    "nEpochs = data[0][0][0].shape[0]\n",
    "n = len(data[0][0])\n",
    "fig = pl.figure(figsize=tuple(np.array((6.,4.))/2.54)); ax = pl.axes()\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "for j in range(n):\n",
    "    pl.plot(np.linspace(1,nEpochs,nEpochs),1. - np.convolve(np.pad(data[0][0][j], (50,50), mode='edge'),kernel,mode='same')[50:-50], linewidth=1.0, color=np.array([j,j,j])/10.)\n",
    "for j in range(datam[0].shape[1]):\n",
    "    pl.plot(np.linspace(1,nEpochs,nEpochs),1. - np.convolve(np.pad(datam[0][:,j], (50,50), mode='edge'),kernel,mode='same')[50:-50], linewidth=1.0, color='g')\n",
    "\n",
    "ax.xaxis.set_ticks((0,nEpochs)); ax.set_yscale('log'); ax.yaxis.set_ticks([0.02,0.05,0.2,0.5]); ax.set_ylim(ymin=0.02, ymax=0.6)\n",
    "ax.get_yaxis().set_major_formatter(mpl.ticker.ScalarFormatter())\n",
    "pl.savefig('/home/jb739/sheffield/proj/esn_feedback/figs/swLR/acc_multiTransferLearning.svg', format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.load('/home/jb739/sheffield/proj/esn_feedback/data/FB2_LocMin/wTran11113.pt')\n",
    "mu.setupMatplotlib()\n",
    "kernel = np.ones(50)/50\n",
    "nEpochs = data[0][0][0].shape[0]\n",
    "n = len(data[0][0])\n",
    "fig = pl.figure(figsize=tuple(np.array((6.,4.))/2.54)); ax = pl.axes()\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "k=[4,7,5,9]\n",
    "for d,j in enumerate(k):\n",
    "    pl.plot(np.linspace(1,nEpochs,nEpochs),1. - np.convolve(np.pad(data[0][0][j], (50,50), mode='edge'),kernel,mode='same')[50:-50], linewidth=1.0, color=np.array([j,j,j])/10.)\n",
    "ax.xaxis.set_ticks((0,nEpochs)); ax.set_yscale('log'); ax.yaxis.set_ticks([0.02,0.05,0.2,0.5]); ax.set_ylim(ymin=0.02, ymax=0.6)\n",
    "ax.get_yaxis().set_major_formatter(mpl.ticker.ScalarFormatter())\n",
    "\n",
    "fig = pl.figure(figsize=tuple(np.array((25.,15.))/2.54)); ax = pl.axes()\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "pl.plot(w[5][0][:50,0]);pl.plot(w[9][0][:50,0]);pl.plot(w[0][0][:50,0])\n",
    "# pl.plot(w[5][1]);pl.plot(w[9][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esn_feedback_ana(key,**kwa):\n",
    "\n",
    "    ### Load accuracy data\n",
    "    if key=='loadData':\n",
    "        # kwa needs: modName, expName, dataName\n",
    "        baseDirName = '/home/jb739/sheffield/proj/esn_feedback/data/'+kwa['modName']+'_'+kwa['expName']\n",
    "        dirNames = gl.glob(baseDirName+'_*'); dirNames.sort()\n",
    "        complete = torch.load('/home/jb739/sheffield/proj/esn_feedback/data/'+kwa['modName']+'_'+kwa['expName']+'_0/complete.pt') \n",
    "        nLR = complete.shape[0]\n",
    "        data = []; nRuns = []\n",
    "        for j,dirName in enumerate(dirNames): # loop over learning rates\n",
    "            runs = complete[j,:]>0 # Boolean vector of which runs completed\n",
    "            nRuns.append(np.sum(runs.long().numpy())) # Number of completed runs\n",
    "            data.append([]) # Add list element for this learning rate\n",
    "            if nRuns[j]>0:  # If there are any runs, do:\n",
    "                fileNames = gl.glob(dirName+'/'+kwa['dataName']+'*'); fileNames.sort()\n",
    "                for k, fileName in enumerate(fileNames): # loop over runs (random seeds)\n",
    "                    data[j].append(torch.load(fileNames[k])) # Load file data (for accuracies, this is a list)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    ### Plot accuracies as error (1 - accuracy)\n",
    "    if key=='plotAcc':\n",
    "        # kwa needs: acc, saveFlag, figDir, figName\n",
    "        mu.setupMatplotlib()\n",
    "        acc = kwa['acc']\n",
    "        nEpochs = acc[0].shape[0]\n",
    "        n = len(acc)\n",
    "        col1 = np.array(tuple(x**2 for x in (0.,1.,0.3))); col2 = np.array(tuple(x**2 for x in (0.8, 0., 1.)))\n",
    "        colShade = np.linspace(0.,1.,n)\n",
    "        kernel = np.ones(50)/50\n",
    "        fig = pl.figure(figsize=tuple(np.array((6.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        for j in range(n):\n",
    "            col = tuple(np.sqrt(colShade[j]**2 * col2 + colShade[n-1-j]**2 * col1))\n",
    "            if np.size(acc[j])>0:\n",
    "                pl.plot(np.linspace(1,nEpochs,nEpochs),1. - np.convolve(np.pad(np.mean(acc[j],1), (50,50), mode='edge'),kernel,mode='same')[50:-50], linewidth=1.0, color=col)\n",
    "        ax.xaxis.set_ticks((0,nEpochs)); ax.set_yscale('log'); ax.yaxis.set_ticks([0.02,0.05,0.2,0.5]); ax.set_ylim(ymin=0.02, ymax=0.6)\n",
    "        ax.get_yaxis().set_major_formatter(mpl.ticker.ScalarFormatter())\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'/'+kwa['figName']+'.svg', format=\"svg\")\n",
    "    \n",
    "    ### Load saved responses\n",
    "    if key=='loadResp':\n",
    "        # Return list of responses. Eac list element is for a different seed. Responses are from one layer\n",
    "        # kwa needs: modName, expName, dataName, selectLR, maxNSeeds, layer\n",
    "        baseDirName = '/home/jb739/sheffield/proj/esn_feedback/data/'+kwa['modName']+'_'+kwa['expName']+'_*'\n",
    "        dataDirNames = gl.glob(baseDirName); dataDirNames.sort()\n",
    "        data = []\n",
    "        for j,d in enumerate(dataDirNames): # For each learning rate\n",
    "            if j!=kwa['selectLR']: # For selected best learning rate\n",
    "                continue\n",
    "            baseFileName = d+'/'+kwa['dataName']+'*'\n",
    "            fNames = gl.glob(baseFileName); fNames.sort()\n",
    "            for f, fName in enumerate(fNames): # For each seed\n",
    "                if f==kwa['maxNSeeds']: # Only process maxNSeeds seeds\n",
    "                    break\n",
    "                # Load response data from fName (1 layer only)\n",
    "                print(fName)\n",
    "                r = torch.load(fName)[kwa['layer']] \n",
    "                # Create new list element for r-data, with shape [#iterations saved, #samples, #neurons x #time steps]\n",
    "                # data.append(np.reshape(r, (r.shape[0], r.shape[1], r.shape[2]*r.shape[3]))) \n",
    "                data.append(r) \n",
    "\n",
    "        return data\n",
    "    \n",
    "    ### Compute principle components\n",
    "    if key=='computePCA':\n",
    "        # kwa needs: data\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.manifold import TSNE\n",
    "        from scipy import stats\n",
    "        # Preprocess data\n",
    "        if len(kwa['data'].shape)>3:\n",
    "            data = kwa['data'][-1,:,:,:]\n",
    "        else:\n",
    "            data = kwa['data']\n",
    "        # for j in range(data.shape[0]):\n",
    "        #     data[j,:,:] = stats.zscore(data[j,:,:])\n",
    "        # Init PCA object\n",
    "        pca = PCA(n_components=np.minimum(data.shape[0],data.shape[1]))\n",
    "        # Perform PCA and return transformed data (last saved time point)\n",
    "        # p = pca.fit_transform(np.mean(data[-2,:,:]))\n",
    "        print(np.sum(np.double(np.isnan(data))))\n",
    "        p = pca.fit_transform(np.mean(data[:,:,-5:], axis=2))\n",
    "\n",
    "        return p, pca\n",
    "    \n",
    "    ### Plot class trajectories and clusters in PCA space\n",
    "    if key=='plotPCA':\n",
    "        # kwa needs: data, pca, pc, saveTime, saveFlag, figDir, figSuffix\n",
    "        ### Process inputs\n",
    "        data = kwa['data'] # Responses\n",
    "        pca = kwa['pca'] # PCA function\n",
    "        pc = kwa['pc'] # 1st 2 PCs that define PC space\n",
    "        var = np.cumsum(np.array(list(x*100 for x in pca.explained_variance_ratio_)))\n",
    "        if len(kwa['data'].shape)>3:\n",
    "            nt = data.shape[3] # No. time steps\n",
    "            nn = data.shape[2] # No. neurons\n",
    "            ns = data.shape[1] # No. samples\n",
    "        else:\n",
    "            nt = data.shape[2]\n",
    "            nn = data.shape[1]\n",
    "            ns = data.shape[0]\n",
    "        nspc = int(ns/10)  # No. samples per cluster\n",
    "        mapData = np.zeros((ns, 2, nt))\n",
    "        if len(kwa['data'].shape)>3:\n",
    "            for t in range(nt):\n",
    "                mapData[:,:,t] = pca.transform(data[kwa['saveTime'],:,:,t])[:,0:2]\n",
    "        else:\n",
    "            for t in range(nt):\n",
    "                mapData[:,:,t] = pca.transform(data[:,:,t])[:,0:2]\n",
    "        \n",
    "        ### Generate figures\n",
    "        mu.setupMatplotlib()\n",
    "        # Plot variance explained\n",
    "        fig = pl.figure(figsize=tuple(np.array((2.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        pl.scatter(np.linspace(1,ns,var.shape[0]), var, s=3, color='k', alpha=0.5, linewidths=0)\n",
    "        pl.plot(np.linspace(1,ns,2), np.ones(2)*90, '--', color=(0.5, 0.5, 0.5), linewidth=0.5)\n",
    "        ax.set_xscale('log')\n",
    "        # pl.xticks([1,10,100], ['1','10','100'], minor=[2,3,4,5,6,7,8,9,20,30,40,50,60,70,80,90])\n",
    "        ax.xaxis.set_ticks((1, 20, 200)); ax.yaxis.set_ticks((0,100))\n",
    "        ax.get_xaxis().set_major_formatter(mpl.ticker.ScalarFormatter())\n",
    "        ax.set_xlim(xmin=0.5, xmax=200); ax.set_ylim(ymin=0, ymax=100)\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'varExplained_'+kwa['figSuffix']+'.svg', format=\"svg\")\n",
    "        # Plot PCA clusters\n",
    "        fig = pl.figure(figsize=tuple(np.array((4.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        for j in range(10):\n",
    "            col = mpl.colormaps['tab10'].colors[j]\n",
    "            pl.scatter(pc[j*nspc:(j+1)*nspc,0], pc[j*nspc:(j+1)*nspc,1], s=3, color=col)\n",
    "        ax.xaxis.set_ticks((-10,0,10)); ax.yaxis.set_ticks((-10,0,10))\n",
    "        ax.set_xlim(xmin=-16, xmax=16); ax.set_ylim(ymin=-16, ymax=16)\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'pcaClusters_'+kwa['figSuffix']+'.svg', format=\"svg\")\n",
    "        ### Plot mean class response trajectory in PC space\n",
    "        fig = pl.figure(figsize=tuple(np.array((4.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        scale = np.logspace(-1,0,nt)\n",
    "        for j in range(10):\n",
    "            col = mpl.colormaps['tab10'].colors[j]\n",
    "            for t in range(mapData.shape[2]-1):\n",
    "                colT = tuple(x**scale[t] for x in col)\n",
    "                pl.plot(np.mean(mapData[j*nspc:(j+1)*nspc,0,t:t+2], axis=0), np.mean(mapData[j*nspc:(j+1)*nspc,1,t:t+2], axis=0), color=colT, linewidth=1)\n",
    "        ax.xaxis.set_ticks((-10,0,10)); ax.yaxis.set_ticks((-10,0,10))\n",
    "        ax.set_xlim(xmin=-16, xmax=16); ax.set_ylim(ymin=-16, ymax=16)\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'pcaTraj_'+kwa['figSuffix']+'.svg', format=\"svg\")\n",
    "    \n",
    "    ### Compute clustering index\n",
    "    if key=='clusterIndex':\n",
    "        # kwa needs: data\n",
    "        ### Compute Silhuoette Index\n",
    "        if len(kwa['data'].shape)>3:\n",
    "            r = np.mean(kwa['data'][-1,:,:,-5:], axis=2)\n",
    "        else:\n",
    "            r = np.mean(kwa['data'][:,:,-5:], axis=2)\n",
    "        ns = r.shape[0] # No. samples\n",
    "        nc = 10 # No. clusters\n",
    "        nspc = int(ns/nc)  # No. samples per cluster\n",
    "        dist = np.zeros((ns, ns))\n",
    "        # Compute distances between samples\n",
    "        for j in range(ns):\n",
    "            dist[:,j] = np.sqrt(np.sum((r - np.roll(r, -j, axis=0))**2, axis=1))\n",
    "        # Rearrange dist to yield distance matrix\n",
    "        # Fill diagonal of dist matrix with NaNs\n",
    "        for j in range(ns):\n",
    "            dist[j,:] = np.roll(np.expand_dims(dist[j,:], axis=0), j, axis=1)\n",
    "            dist[j,j] = np.NaN\n",
    "        # Compute mean distance from each sample to each cluster\n",
    "        mDist = np.zeros((ns, nc))\n",
    "        for j in range(nc):\n",
    "            mDist[:,j] = np.nanmean(dist[:,j*nspc:(j+1)*nspc], axis=1)\n",
    "        # Rearrange mDist so that each sample's own cluster is in first column\n",
    "        for j in range(nc):\n",
    "            mDist[j*nspc:(j+1)*nspc,:] = np.roll(mDist[j*nspc:(j+1)*nspc,:], -j, axis=1)\n",
    "        # Calculate Silhuoette Index\n",
    "        a = np.expand_dims(mDist[:,0], axis=1); b = np.expand_dims(np.min(mDist[:,1:], axis=1), axis=1)\n",
    "        SI = np.divide(b - a, np.expand_dims(np.max(np.concatenate((a,b), axis=1), axis=1), axis=1))\n",
    "\n",
    "        return SI\n",
    "    \n",
    "    ### Plot cluster indeces\n",
    "    if key=='plotClusterIndex':\n",
    "        # kwa needs: ci, figDir, figSuffix, saveFlag\n",
    "        ci = kwa['ci']\n",
    "        nc = 10 # No. classes\n",
    "        ns = ci.shape[0] # No. samples\n",
    "        nspc = int(ns/nc) # No. samples per cluster\n",
    "        mu.setupMatplotlib()\n",
    "        fig = pl.figure(figsize=tuple(np.array((4.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        for j in range(10):\n",
    "            col = mpl.colormaps['tab10'].colors[j]\n",
    "            # pl.plot(np.linspace(j*10+1,(j+1)*10,10), ci[j*10:(j+1)*10], linewidth=1, color=col)\n",
    "            pl.scatter(np.linspace(j*nspc+1,(j+1)*nspc,nspc), ci[j*nspc:(j+1)*nspc], s=3, color=col)\n",
    "        pl.plot(np.linspace(0,ns+1,2), np.ones(2)*np.mean(ci), '--', color=(0.5, 0.5, 0.5), linewidth=0.5)\n",
    "        ax.xaxis.set_ticks((1,200)); ax.yaxis.set_ticks((-1,0,1))\n",
    "        ax.set_xlim(xmin=0, xmax=201); ax.set_ylim(ymin=-1, ymax=1)\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'clusterIndex_'+kwa['figSuffix']+'.svg', format=\"svg\")\n",
    "\n",
    "    ### Plot mean cluster indeces across runs for all models\n",
    "    if key=='allSI':\n",
    "        # kwa needs: prefix, lr_index, layer\n",
    "        # Load data and compute silhouette indeces\n",
    "\n",
    "        baseName = '/home/jb739/sheffield/proj/esn_feedback/data/'\n",
    "        models = ('0', '1', '2')\n",
    "        experiment = 'swLR'\n",
    "        si = np.zeros((len(models), 5))\n",
    "        for j, model in enumerate(models):\n",
    "            dirNames = gl.glob(baseName+kwa['prefix']+model+'_'+experiment+'_*'); dirNames.sort(); \n",
    "            print(dirNames)\n",
    "            dirName = dirNames[kwa['lr_index']] \n",
    "            print(dirName)\n",
    "            dataName = 'respSave'\n",
    "            r = esn_feedback_ana('loadResp',modName=kwa['prefix']+model,expName=experiment,dataName=dataName,selectLR=kwa['lr_index'],maxNSeeds=5,layer=kwa['layer'])\n",
    "            for k in range(len(r)):\n",
    "                si[j,k] = np.mean(esn_feedback_ana('clusterIndex',data=r[k]))\n",
    "\n",
    "        return si\n",
    "        \n",
    "    ### Plot all mean SIs\n",
    "    if key=='plotAllSI':\n",
    "        # kwa needs: si, figDir, layer, prefix\n",
    "        si = kwa['si']\n",
    "        mSI = np.mean(si,axis=1)\n",
    "        sSI = np.std(si, axis=1)\n",
    "        col1 = (0.5,0,0,0.33) if kwa['layer']==2 else (0,0,0,0.33)\n",
    "        col2 = (0.5,0,0,1) if kwa['layer']==2 else (0,0,0,1)\n",
    "        mu.setupMatplotlib()\n",
    "        fig = pl.figure(figsize=tuple(np.array((4.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        for j in range(si.shape[0]):\n",
    "            pl.scatter(j+np.random.uniform(-0.25,0.25,(si.shape[1],1)), si[j,:], c=col1, s=3, edgecolors='none')\n",
    "        pl.errorbar(list(range(3)), mSI, yerr=sSI, fmt='o', color=col2, markersize=3, markeredgecolor='none')\n",
    "        ax.xaxis.set_ticks(list(range(3))); ax.yaxis.set_ticks([0.1,0.4,0.7])\n",
    "        ax.set_xlim(xmin=-0.5, xmax=2.5); ax.set_ylim(ymin=0.1, ymax=0.7)\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'/allSI'+kwa['prefix']+'_L'+str(kwa['layer'])+'_'+'.svg', format=\"svg\")\n",
    "\n",
    "    ### Plot histograms of DW (weight changes)\n",
    "    if key=='plotDW':\n",
    "        # kwa needs: modName, expName, dataName, figDir, layer (count from 0, do not use -ve index), time (saved time point)\n",
    "        baseDirName = '/home/jb739/sheffield/proj/esn_feedback/data/'+kwa['modName']+'_'+kwa['expName']; print(baseDirName)\n",
    "        dirNames = gl.glob(baseDirName+'_*'); dirNames.sort(); \n",
    "        complete = torch.load('/home/jb739/sheffield/proj/esn_feedback/data/'+kwa['modName']+'_'+kwa['expName']+'_0/complete.pt') \n",
    "        nLR = complete.shape[0]\n",
    "        dwEdges = torch.logspace(-10,-3,51) # Edges used to build histogram\n",
    "        histogram = [] # init histograms\n",
    "        fWeights = []  # init count for number of changing weights\n",
    "        dwMode = [] # Init modal DW as a function of time\n",
    "        for j, dirName in enumerate(dirNames): # Loop over learning rates\n",
    "            runs = complete[j,:]>0         # Boolean vector of which runs completed\n",
    "            nRuns= np.sum(runs.long().numpy())      # Number of completed runs\n",
    "            if nRuns>0:  # If there are any runs, do:    \n",
    "                histogram.append(np.zeros((50))) # Init storage for dw histograms\n",
    "                dwMode.append(np.ones((25))) # Init storage for dwMode\n",
    "                fileNames = gl.glob(dirName+'/dw*'); fileNames.sort() # Get run filenames\n",
    "                for k, fileName in enumerate(fileNames): # for all other completed runs\n",
    "                    if complete[j,k]>0:\n",
    "                        h = torch.load(fileName)[kwa['layer']]\n",
    "                        histogram[j] += h[:,kwa['time']]\n",
    "                        dwMode[j] = np.multiply(dwMode[j],dwEdges[np.argmax(h, axis=0)])\n",
    "                histogram[j] /= nRuns # Normalise by number of successful runs\n",
    "                dwMode[j] = np.power(dwMode[j], float(1/nRuns)) # Geometric mean of learning rates\n",
    "                fWeights.append(histogram[j].sum()/(par.Ns[kwa['layer']]*par.Ns[kwa['layer']+1])) # Fraction of weights that change\n",
    "            else:\n",
    "                # if no completed runs, append empty arrays\n",
    "                histogram.append([])\n",
    "                fWeights.append([])\n",
    "                dwMode.append([])\n",
    "        \n",
    "        # Plot DW histograms\n",
    "        mu.setupMatplotlib()\n",
    "        fig = pl.figure(figsize=tuple(np.array((6.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        col1 = np.array(tuple(x**2 for x in (0.,1.,0.3))); col2 = np.array(tuple(x**2 for x in (0.8, 0., 1.)))\n",
    "        colShade = np.linspace(0.,1.,nLR)\n",
    "        for j, hist in enumerate(histogram):\n",
    "            if len(hist)>0 and fWeights[j]>0.25: # if there is a histogram (i.e. at least one successful run)\n",
    "                col = tuple(np.sqrt(colShade[j]**2 * col2 + colShade[nLR-1-j]**2 * col1)) # set colour for this learning rate\n",
    "                pl.plot(dwEdges[:50],hist / hist.sum(), linewidth=1.0, color=col) # plot histogram\n",
    "                print(hist.sum())\n",
    "            else:\n",
    "                print([])\n",
    "        ax.set_ylim(ymin=0, ymax=0.2)\n",
    "        pl.xscale('log')\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'/dwHistogram_'+kwa['modName']+'.svg', format=\"svg\")\n",
    "        \n",
    "        # Plot number of changing weights\n",
    "        fig = pl.figure(figsize=tuple(np.array((2.,1.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        for j, frac in enumerate(fWeights):\n",
    "            if fWeights[j]>0.25:\n",
    "                col = tuple(np.sqrt(colShade[j]**2 * col2 + colShade[nLR-1-j]**2 * col1)) # set colour for this learning rate\n",
    "                pl.scatter(j, frac, s=3, color=col)\n",
    "        ax.xaxis.set_ticks([]); ax.yaxis.set_ticks((0,1))\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'/dwCount_inset_'+kwa['modName']+'.svg', format=\"svg\")\n",
    "\n",
    "        # Plot evolution of modal DW\n",
    "        fig = pl.figure(figsize=tuple(np.array((6.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        for j, mode in enumerate(dwMode):\n",
    "            if len(mode)>0:\n",
    "                col = tuple(np.sqrt(colShade[j]**2 * col2 + colShade[nLR-1-j]**2 * col1)) # set colour for this learning rate\n",
    "                pl.plot(np.linspace(0,par.nEpochs,25), mode, linewidth=1.0, color=col)\n",
    "        pl.yscale('log'); ax.yaxis.set_ticks([1e-7,1e-5,1e-3]); ax.yaxis.set_ticklabels(['$10^{-7}$','$10^{-5}$','$10^{-3}$']); ax.xaxis.set_ticks([0,5000]); ax.set_ylim(ymin=1e-7, ymax=dwEdges[-1])\n",
    "        # ax.get_yaxis().set_major_formatter(mpl.ticker.ScalarFormatter())\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'/dwModeEvo_'+kwa['modName']+'.svg', format=\"svg\")\n",
    "      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select and run analyses\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot accuracies for multiple learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'out2FB2'\n",
    "experiment = 'swLR'\n",
    "key = 'loadData'; dataName = 'accValTa'\n",
    "acc = esn_feedback_ana(key,modName=model,expName=experiment,dataName=dataName)\n",
    "\n",
    "# Concatenate runs for plotting\n",
    "accpl = []\n",
    "for j in range(len(acc)):\n",
    "    accpl.append([])\n",
    "    accpl[j] = np.zeros((acc[j][0][0].shape[0],len(acc[j])))\n",
    "    for k in range(len(acc[j])):\n",
    "        accpl[j][:,k] = acc[j][k][0]\n",
    "\n",
    "key = 'plotAcc'; saveFlag = True; \n",
    "esn_feedback_ana(key,acc=accpl,saveFlag=saveFlag, figDir='./figs/swLR/', figName=dataName+'_'+model)\n",
    "\n",
    "# To estimate which LR to use for further analyses\n",
    "mx = 0; mxind = 0\n",
    "for i in range(len(accpl)):\n",
    "    if np.size(accpl[i])>0:\n",
    "        mn = np.mean(np.mean(accpl[i][-100:,:], axis=0))\n",
    "        print(f'{i}: {mn}')\n",
    "        if mn>mx:\n",
    "            mx = mn; mxind = i\n",
    "    else:\n",
    "        print('None')\n",
    "print(f'Max is LR-index {mxind}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot transfer learning accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'out2FB0'\n",
    "experiment = 'swLR'\n",
    "key = 'loadData'; dataName = 'out_accValTa'\n",
    "# load accuracies (nested lists, acc[#learning rates][#runs per LR][# transfer learning instances])\n",
    "acc = esn_feedback_ana(key,modName=model,expName=experiment,dataName=dataName)\n",
    "# Concatenate runs for plotting\n",
    "accpl = []\n",
    "for j in range(len(acc)):\n",
    "    accpl.append([])\n",
    "    accpl[j] = np.zeros((acc[j][0][0].shape[0],len(acc[j])))\n",
    "    for k in range(len(acc[j])):\n",
    "        accpl[j][:,k] = acc[j][k][0]\n",
    "\n",
    "key = 'plotAcc'; saveFlag = False; \n",
    "esn_feedback_ana(key,acc=accpl,saveFlag=saveFlag, figDir='./figs/swLR/', figName=dataName+'_'+model)\n",
    "\n",
    "# To estimate which LR to use for further analyses\n",
    "mx = 0; mxind = 0\n",
    "for i in range(len(accpl)):\n",
    "    if np.size(accpl[i])>0:\n",
    "        mn = np.mean(np.mean(accpl[i][-100:,:], axis=0))\n",
    "        print(f'{i}: {mn}')\n",
    "        if mn>mx:\n",
    "            mx = mn; mxind = i\n",
    "    else:\n",
    "        print('None')\n",
    "print(f'Max is LR-index {mxind}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform PCA and clustering analyses on final hidden layer responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[0].shape\n",
    "fig = pl.figure(figsize=tuple(np.array((8.,8.))/2.54)); ax = pl.axes()\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "pl.plot(r[0][0,21,:,:].transpose())\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot response examples\n",
    "saveFlag=False; LR_index = 3; model = 'out2proFB2'; layer=1\n",
    "# Load data\n",
    "experiment = 'swLR'; key = 'loadResp'; dataName = 'respSave11113'\n",
    "r = esn_feedback_ana(key,modName=model,expName=experiment,dataName=dataName,selectLR=LR_index,maxNSeeds=1,layer=layer)\n",
    "# Compute principle components\n",
    "key = 'computePCA'\n",
    "p, *pca = esn_feedback_ana(key,data=r[0])\n",
    "# Plot PCs\n",
    "key = 'plotPCA'; figSuffix=model+'_LR'+str(LR_index)+'_'+'layer'+str(layer)+'_'+dataName[-5:]\n",
    "esn_feedback_ana(key,data=r[0], pca=pca[0], pc=p, saveTime=-1, saveFlag=saveFlag, figDir='./figs/swLR/', figSuffix=figSuffix)\n",
    "# Compute Clustering Index\n",
    "key = 'clusterIndex'\n",
    "SI = esn_feedback_ana(key,data=r[0])\n",
    "# Plot cluster indeces\n",
    "key = 'plotClusterIndex'; figDir = './figs/swLR/'\n",
    "esn_feedback_ana(key, ci=SI, figDir=figDir, figSuffix=figSuffix, saveFlag=saveFlag)\n",
    "# Plot mean SI across runs for all models\n",
    "key = 'plotMeanSI'; \n",
    "esn_feedback_ana(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot results summary for all models\n",
    "key = 'allSI'; layer = 1; prefix='proFB'\n",
    "si = esn_feedback_ana(key, prefix=prefix, lr_index=4, layer=layer)\n",
    "key = 'plotAllSI'; figDir='./figs/swLR'\n",
    "esn_feedback_ana(key, si=si, figDir=figDir, layer=layer, prefix=prefix, saveFlag=True)\n",
    "print(si)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot feedback weight evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=torch.load('/home/jb739/sheffield/proj/esn_feedback/data/metFB3_swLR_4/weightSave11117.pt')\n",
    "fig = pl.figure(figsize=tuple(np.array((20.,5.))/2.54)); ax = pl.axes()\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "for j in range(0,1000,100):\n",
    "    pl.plot(np.linspace(1,5000,26),weights[::2,j,:].transpose(), linewidth=0.5)\n",
    "ax.xaxis.set_ticks((0,5000)); ax.yaxis.set_ticks((-.05,0,.05)); ax.set_ylim(-.5,.5)\n",
    "print(weights[0,0,:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot evolution of mean weight changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=torch.load('/home/jb739/sheffield/proj/esn_feedback/data/out2FB2_swLR_3/dw11117.pt')\n",
    "fig = pl.figure(figsize=tuple(np.array((15.,15.))/2.54)); ax = pl.axes()\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "for j in range(len(w)):\n",
    "    pl.plot(w[j][:,-1]/np.sum(w[j][:,-1]), c=[j/8,j/8,j/8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFlag = True\n",
    "key = 'plotDW'; model = 'out2FB2'; experiment = 'swLR'\n",
    "esn_feedback_ana(key, saveFlag=saveFlag, modName=model, expName=experiment, figDir='./figs/swLR/', layer=4, time=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
