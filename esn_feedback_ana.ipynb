{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as gl\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib as mpl\n",
    "import myutils as mu\n",
    "import params_feedback as par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modName = 'FB2'\n",
    "expName = 'LocMin'\n",
    "dataName = 'out_accValTa'\n",
    "baseDirName = '/home/jb739/sheffield/proj/esn_feedback/data/'+modName+'_'+expName\n",
    "dirNames = gl.glob(baseDirName); dirNames.sort()\n",
    "# complete = torch.load('/home/jb739/sheffield/proj/esn_feedback/data/'+modName+'_'+expName+'/complete.pt') \n",
    "# nLR = complete.shape[0]\n",
    "data = []; nRuns = []\n",
    "for j,dirName in enumerate(dirNames): # loop over learning rates\n",
    "    # runs = complete[j,:]>0 # Boolean vector of which runs completed\n",
    "    # nRuns.append(np.sum(runs.long().numpy())) # Number of completed runs\n",
    "    data.append([])\n",
    "    # if nRuns[j]>0:  # If there are any runs, do:\n",
    "    fileNames = gl.glob(dirName+'/'+dataName+'*'); fileNames.sort()\n",
    "    for k, fileName in enumerate(fileNames): # loop over runs (random seeds)\n",
    "        data[j].append(torch.load(fileName))\n",
    "\n",
    "modName = 'FB2'\n",
    "expName = 'swLR'\n",
    "dataName = 'out_accValTa'\n",
    "baseDirName = '/home/jb739/sheffield/proj/esn_feedback/data/'+modName+'_'+expName\n",
    "dirNames = gl.glob(baseDirName+'_*'); dirNames.sort()\n",
    "complete = torch.load('/home/jb739/sheffield/proj/esn_feedback/data/'+modName+'_'+expName+'_0/complete.pt') \n",
    "nLR = complete.shape[0]\n",
    "datam = []; nRuns = []\n",
    "j = 4; dirName = dirNames[j]\n",
    "fileNames = gl.glob(dirName+'/'+dataName+'*'); fileNames.sort()\n",
    "temp = torch.load(fileNames[0])                \n",
    "datam.append(np.expand_dims(np.array(torch.load(fileNames[0])), axis=1))\n",
    "for k in range(1,len(fileNames)): # loop over runs (random seeds)\n",
    "    datam[0] = np.concatenate((datam[0], np.expand_dims(np.array(torch.load(fileNames[k])), axis=1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.setupMatplotlib()\n",
    "kernel = np.ones(50)/50\n",
    "nEpochs = data[0][0][0].shape[0]\n",
    "n = len(data[0][0])\n",
    "fig = pl.figure(figsize=tuple(np.array((6.,4.))/2.54)); ax = pl.axes()\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "for j in range(n):\n",
    "    pl.plot(np.linspace(1,nEpochs,nEpochs),1. - np.convolve(np.pad(data[0][0][j], (50,50), mode='edge'),kernel,mode='same')[50:-50], linewidth=1.0, color=np.array([j,j,j])/10.)\n",
    "for j in range(datam[0].shape[1]):\n",
    "    pl.plot(np.linspace(1,nEpochs,nEpochs),1. - np.convolve(np.pad(datam[0][:,j], (50,50), mode='edge'),kernel,mode='same')[50:-50], linewidth=1.0, color='g')\n",
    "\n",
    "ax.xaxis.set_ticks((0,nEpochs)); ax.set_yscale('log'); ax.yaxis.set_ticks([0.02,0.05,0.2,0.5]); ax.set_ylim(ymin=0.02, ymax=0.6)\n",
    "ax.get_yaxis().set_major_formatter(mpl.ticker.ScalarFormatter())\n",
    "pl.savefig('/home/jb739/sheffield/proj/esn_feedback/figs/swLR/acc_multiTransferLearning.svg', format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.load('/home/jb739/sheffield/proj/esn_feedback/data/FB2_LocMin/wTran11113.pt')\n",
    "mu.setupMatplotlib()\n",
    "kernel = np.ones(50)/50\n",
    "nEpochs = data[0][0][0].shape[0]\n",
    "n = len(data[0][0])\n",
    "fig = pl.figure(figsize=tuple(np.array((6.,4.))/2.54)); ax = pl.axes()\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "k=[4,7,5,9]\n",
    "for d,j in enumerate(k):\n",
    "    pl.plot(np.linspace(1,nEpochs,nEpochs),1. - np.convolve(np.pad(data[0][0][j], (50,50), mode='edge'),kernel,mode='same')[50:-50], linewidth=1.0, color=np.array([j,j,j])/10.)\n",
    "ax.xaxis.set_ticks((0,nEpochs)); ax.set_yscale('log'); ax.yaxis.set_ticks([0.02,0.05,0.2,0.5]); ax.set_ylim(ymin=0.02, ymax=0.6)\n",
    "ax.get_yaxis().set_major_formatter(mpl.ticker.ScalarFormatter())\n",
    "\n",
    "fig = pl.figure(figsize=tuple(np.array((25.,15.))/2.54)); ax = pl.axes()\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "pl.plot(w[5][0][:50,0]);pl.plot(w[9][0][:50,0]);pl.plot(w[0][0][:50,0])\n",
    "# pl.plot(w[5][1]);pl.plot(w[9][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esn_feedback_ana(key,**kwa):\n",
    "\n",
    "    ### Load accuracy data\n",
    "    if key=='loadData':\n",
    "        # kwa needs: modName, expName, dataName\n",
    "        baseDirName = '/home/jb739/sheffield/proj/esn_feedback/data/'+kwa['modName']+'_'+kwa['expName']\n",
    "        dirNames = gl.glob(baseDirName+'_*'); dirNames.sort()\n",
    "        complete = torch.load('/home/jb739/sheffield/proj/esn_feedback/data/'+kwa['modName']+'_'+kwa['expName']+'_0/complete.pt') \n",
    "        nLR = complete.shape[0]\n",
    "        data = []; nRuns = []\n",
    "        for j,dirName in enumerate(dirNames): # loop over learning rates\n",
    "            runs = complete[j,:]>0 # Boolean vector of which runs completed\n",
    "            nRuns.append(np.sum(runs.long().numpy())) # Number of completed runs\n",
    "            data.append([]) # Add list element for this learning rate\n",
    "            if nRuns[j]>0:  # If there are any runs, do:\n",
    "                fileNames = gl.glob(dirName+'/'+kwa['dataName']+'*'); fileNames.sort()\n",
    "                for k, fileName in enumerate(fileNames): # loop over runs (random seeds)\n",
    "                    data[j].append(torch.load(fileNames[k])) # Load file data (for accuracies, this is a list)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    ### Plot accuracies as error (1 - accuracy)\n",
    "    if key=='plotAcc':\n",
    "        # kwa needs: acc, saveFlag, figDir, figName\n",
    "        mu.setupMatplotlib()\n",
    "        acc = kwa['acc']\n",
    "        nEpochs = acc[0].shape[0]\n",
    "        n = len(acc)\n",
    "        col1 = np.array(tuple(x**2 for x in (0.,1.,0.3))); col2 = np.array(tuple(x**2 for x in (0.8, 0., 1.)))\n",
    "        colShade = np.linspace(0.,1.,n)\n",
    "        kernel = np.ones(50)/50\n",
    "        fig = pl.figure(figsize=tuple(np.array((6.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        for j in range(n):\n",
    "            col = tuple(np.sqrt(colShade[j]**2 * col2 + colShade[n-1-j]**2 * col1))\n",
    "            if np.size(acc[j])>0:\n",
    "                pl.plot(np.linspace(1,nEpochs,nEpochs),1. - np.convolve(np.pad(np.mean(acc[j],1), (50,50), mode='edge'),kernel,mode='same')[50:-50], linewidth=1.0, color=col)\n",
    "        ax.xaxis.set_ticks((0,nEpochs)); ax.set_yscale('log'); ax.yaxis.set_ticks([0.02,0.05,0.2,0.5]); ax.set_ylim(ymin=0.02, ymax=0.6)\n",
    "        ax.get_yaxis().set_major_formatter(mpl.ticker.ScalarFormatter())\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'/'+kwa['figName']+'.svg', format=\"svg\")\n",
    "    \n",
    "    ### Load saved responses\n",
    "    if key=='loadResp':\n",
    "        # Return list of responses. Eac list element is for a different seed. Responses are from one layer\n",
    "        # kwa needs: modName, expName, dataName, selectLR, maxNSeeds, layer\n",
    "        baseDirName = '/home/jb739/sheffield/proj/esn_feedback/data/'+kwa['modName']+'_'+kwa['expName']+'_*'\n",
    "        dataDirNames = gl.glob(baseDirName); dataDirNames.sort()\n",
    "        data = []\n",
    "        for j,d in enumerate(dataDirNames): # For each learning rate\n",
    "            if j!=kwa['selectLR']: # For selected best learning rate\n",
    "                continue\n",
    "            baseFileName = d+'/'+kwa['dataName']+'*'\n",
    "            fNames = gl.glob(baseFileName); fNames.sort()\n",
    "            for f, fName in enumerate(fNames): # For each seed\n",
    "                if f==kwa['maxNSeeds']: # Only process maxNSeeds seeds\n",
    "                    break\n",
    "                # Load response data from fName (1 layer only)\n",
    "                print(fName)\n",
    "                r = torch.load(fName)[kwa['layer']] \n",
    "                # Create new list element for r-data, with shape [#iterations saved, #samples, #neurons x #time steps]\n",
    "                # data.append(np.reshape(r, (r.shape[0], r.shape[1], r.shape[2]*r.shape[3]))) \n",
    "                data.append(r) \n",
    "\n",
    "        return data\n",
    "    \n",
    "    ### Compute principle components\n",
    "    if key=='computePCA':\n",
    "        # kwa needs: data\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.manifold import TSNE\n",
    "        from scipy import stats\n",
    "        # Preprocess data\n",
    "        if len(kwa['data'].shape)>3:\n",
    "            data = kwa['data'][-1,:,:,:]\n",
    "        else:\n",
    "            data = kwa['data']\n",
    "        # for j in range(data.shape[0]):\n",
    "        #     data[j,:,:] = stats.zscore(data[j,:,:])\n",
    "        # Init PCA object\n",
    "        pca = PCA(n_components=np.minimum(data.shape[0],data.shape[1]))\n",
    "        # Perform PCA and return transformed data (last saved time point)\n",
    "        # p = pca.fit_transform(np.mean(data[-2,:,:]))\n",
    "        print(np.sum(np.double(np.isnan(data))))\n",
    "        p = pca.fit_transform(np.mean(data[:,:,-5:], axis=2))\n",
    "\n",
    "        return p, pca\n",
    "    \n",
    "    ### Plot class trajectories and clusters in PCA space\n",
    "    if key=='plotPCA':\n",
    "        # kwa needs: data, pca, pc, saveTime, saveFlag, figDir, figSuffix\n",
    "        ### Process inputs\n",
    "        data = kwa['data'] # Responses\n",
    "        pca = kwa['pca'] # PCA function\n",
    "        pc = kwa['pc'] # 1st 2 PCs that define PC space\n",
    "        var = np.cumsum(np.array(list(x*100 for x in pca.explained_variance_ratio_)))\n",
    "        if len(kwa['data'].shape)>3:\n",
    "            nt = data.shape[3] # No. time steps\n",
    "            nn = data.shape[2] # No. neurons\n",
    "            ns = data.shape[1] # No. samples\n",
    "        else:\n",
    "            nt = data.shape[2]\n",
    "            nn = data.shape[1]\n",
    "            ns = data.shape[0]\n",
    "        nspc = int(ns/10)  # No. samples per cluster\n",
    "        mapData = np.zeros((ns, 2, nt))\n",
    "        if len(kwa['data'].shape)>3:\n",
    "            for t in range(nt):\n",
    "                mapData[:,:,t] = pca.transform(data[kwa['saveTime'],:,:,t])[:,0:2]\n",
    "        else:\n",
    "            for t in range(nt):\n",
    "                mapData[:,:,t] = pca.transform(data[:,:,t])[:,0:2]\n",
    "        \n",
    "        ### Generate figures\n",
    "        mu.setupMatplotlib()\n",
    "        # Plot variance explained\n",
    "        fig = pl.figure(figsize=tuple(np.array((2.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        pl.scatter(np.linspace(1,ns,var.shape[0]), var, s=3, color='k', alpha=0.5, linewidths=0)\n",
    "        pl.plot(np.linspace(1,ns,2), np.ones(2)*90, '--', color=(0.5, 0.5, 0.5), linewidth=0.5)\n",
    "        ax.set_xscale('log')\n",
    "        # pl.xticks([1,10,100], ['1','10','100'], minor=[2,3,4,5,6,7,8,9,20,30,40,50,60,70,80,90])\n",
    "        ax.xaxis.set_ticks((1, 20, 200)); ax.yaxis.set_ticks((0,100))\n",
    "        ax.get_xaxis().set_major_formatter(mpl.ticker.ScalarFormatter())\n",
    "        ax.set_xlim(xmin=0.5, xmax=200); ax.set_ylim(ymin=0, ymax=100)\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'varExplained_'+kwa['figSuffix']+'.svg', format=\"svg\")\n",
    "        # Plot PCA clusters\n",
    "        fig = pl.figure(figsize=tuple(np.array((4.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        for j in range(10):\n",
    "            col = mpl.colormaps['tab10'].colors[j]\n",
    "            pl.scatter(pc[j*nspc:(j+1)*nspc,0], pc[j*nspc:(j+1)*nspc,1], s=3, color=col)\n",
    "        ax.xaxis.set_ticks((-10,0,10)); ax.yaxis.set_ticks((-10,0,10))\n",
    "        ax.set_xlim(xmin=-16, xmax=16); ax.set_ylim(ymin=-16, ymax=16)\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'pcaClusters_'+kwa['figSuffix']+'.svg', format=\"svg\")\n",
    "        ### Plot mean class response trajectory in PC space\n",
    "        fig = pl.figure(figsize=tuple(np.array((4.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        scale = np.logspace(-1,0,nt)\n",
    "        for j in range(10):\n",
    "            col = mpl.colormaps['tab10'].colors[j]\n",
    "            for t in range(mapData.shape[2]-1):\n",
    "                colT = tuple(x**scale[t] for x in col)\n",
    "                pl.plot(np.mean(mapData[j*nspc:(j+1)*nspc,0,t:t+2], axis=0), np.mean(mapData[j*nspc:(j+1)*nspc,1,t:t+2], axis=0), color=colT, linewidth=1)\n",
    "        ax.xaxis.set_ticks((-10,0,10)); ax.yaxis.set_ticks((-10,0,10))\n",
    "        ax.set_xlim(xmin=-16, xmax=16); ax.set_ylim(ymin=-16, ymax=16)\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'pcaTraj_'+kwa['figSuffix']+'.svg', format=\"svg\")\n",
    "    \n",
    "    ### Compute clustering index\n",
    "    if key=='clusterIndex':\n",
    "        # kwa needs: data\n",
    "        ### Compute Silhuoette Index\n",
    "        if len(kwa['data'].shape)>3:\n",
    "            r = np.mean(kwa['data'][-1,:,:,-5:], axis=2)\n",
    "        else:\n",
    "            r = np.mean(kwa['data'][:,:,-5:], axis=2)\n",
    "        ns = r.shape[0] # No. samples\n",
    "        nc = 10 # No. clusters\n",
    "        nspc = int(ns/nc)  # No. samples per cluster\n",
    "        dist = np.zeros((ns, ns))\n",
    "        # Compute distances between samples\n",
    "        for j in range(ns):\n",
    "            dist[:,j] = np.sqrt(np.sum((r - np.roll(r, -j, axis=0))**2, axis=1))\n",
    "        # Rearrange dist to yield distance matrix\n",
    "        # Fill diagonal of dist matrix with NaNs\n",
    "        for j in range(ns):\n",
    "            dist[j,:] = np.roll(np.expand_dims(dist[j,:], axis=0), j, axis=1)\n",
    "            dist[j,j] = np.NaN\n",
    "        # Compute mean distance from each sample to each cluster\n",
    "        mDist = np.zeros((ns, nc))\n",
    "        for j in range(nc):\n",
    "            mDist[:,j] = np.nanmean(dist[:,j*nspc:(j+1)*nspc], axis=1)\n",
    "        # Rearrange mDist so that each sample's own cluster is in first column\n",
    "        for j in range(nc):\n",
    "            mDist[j*nspc:(j+1)*nspc,:] = np.roll(mDist[j*nspc:(j+1)*nspc,:], -j, axis=1)\n",
    "        # Calculate Silhuoette Index\n",
    "        a = np.expand_dims(mDist[:,0], axis=1); b = np.expand_dims(np.min(mDist[:,1:], axis=1), axis=1)\n",
    "        SI = np.divide(b - a, np.expand_dims(np.max(np.concatenate((a,b), axis=1), axis=1), axis=1))\n",
    "\n",
    "        return SI\n",
    "    \n",
    "    ### Plot cluster indeces\n",
    "    if key=='plotClusterIndex':\n",
    "        # kwa needs: ci, figDir, figSuffix, saveFlag\n",
    "        ci = kwa['ci']\n",
    "        nc = 10 # No. classes\n",
    "        ns = ci.shape[0] # No. samples\n",
    "        nspc = int(ns/nc) # No. samples per cluster\n",
    "        mu.setupMatplotlib()\n",
    "        fig = pl.figure(figsize=tuple(np.array((4.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        for j in range(10):\n",
    "            col = mpl.colormaps['tab10'].colors[j]\n",
    "            # pl.plot(np.linspace(j*10+1,(j+1)*10,10), ci[j*10:(j+1)*10], linewidth=1, color=col)\n",
    "            pl.scatter(np.linspace(j*nspc+1,(j+1)*nspc,nspc), ci[j*nspc:(j+1)*nspc], s=3, color=col)\n",
    "        pl.plot(np.linspace(0,ns+1,2), np.ones(2)*np.mean(ci), '--', color=(0.5, 0.5, 0.5), linewidth=0.5)\n",
    "        ax.xaxis.set_ticks((1,200)); ax.yaxis.set_ticks((-1,0,1))\n",
    "        ax.set_xlim(xmin=0, xmax=201); ax.set_ylim(ymin=-1, ymax=1)\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'clusterIndex_'+kwa['figSuffix']+'.svg', format=\"svg\")\n",
    "\n",
    "    ### Plot mean cluster indeces across runs for all models\n",
    "    if key=='allSI':\n",
    "        # kwa needs: prefix, lr_index, layer\n",
    "        # Load data and compute silhouette indeces\n",
    "\n",
    "        baseName = '/home/jb739/sheffield/proj/esn_feedback/data/'\n",
    "        models = ('0', '1', '2')\n",
    "        experiment = 'swLR'\n",
    "        si = np.zeros((len(models), 5))\n",
    "        for j, model in enumerate(models):\n",
    "            dirNames = gl.glob(baseName+kwa['prefix']+model+'_'+experiment+'_*'); dirNames.sort(); \n",
    "            print(dirNames)\n",
    "            dirName = dirNames[kwa['lr_index']] \n",
    "            print(dirName)\n",
    "            dataName = 'respSave'\n",
    "            r = esn_feedback_ana('loadResp',modName=kwa['prefix']+model,expName=experiment,dataName=dataName,selectLR=kwa['lr_index'],maxNSeeds=5,layer=kwa['layer'])\n",
    "            for k in range(len(r)):\n",
    "                si[j,k] = np.mean(esn_feedback_ana('clusterIndex',data=r[k]))\n",
    "\n",
    "        return si\n",
    "        \n",
    "    ### Plot all mean SIs\n",
    "    if key=='plotAllSI':\n",
    "        # kwa needs: si, figDir, layer, prefix\n",
    "        si = kwa['si']\n",
    "        mSI = np.mean(si,axis=1)\n",
    "        sSI = np.std(si, axis=1)\n",
    "        col1 = (0.5,0,0,0.33) if kwa['layer']==2 else (0,0,0,0.33)\n",
    "        col2 = (0.5,0,0,1) if kwa['layer']==2 else (0,0,0,1)\n",
    "        mu.setupMatplotlib()\n",
    "        fig = pl.figure(figsize=tuple(np.array((4.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        for j in range(si.shape[0]):\n",
    "            pl.scatter(j+np.random.uniform(-0.25,0.25,(si.shape[1],1)), si[j,:], c=col1, s=3, edgecolors='none')\n",
    "        pl.errorbar(list(range(3)), mSI, yerr=sSI, fmt='o', color=col2, markersize=3, markeredgecolor='none')\n",
    "        ax.xaxis.set_ticks(list(range(3))); ax.yaxis.set_ticks([0.1,0.4,0.7])\n",
    "        ax.set_xlim(xmin=-0.5, xmax=2.5); ax.set_ylim(ymin=0.1, ymax=0.7)\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'/allSI'+kwa['prefix']+'_L'+str(kwa['layer'])+'_'+'.svg', format=\"svg\")\n",
    "\n",
    "    ### Plot histograms of DW (weight changes)\n",
    "    if key=='plotDW':\n",
    "        # kwa needs: modName, expName, dataName, figDir, layer (count from 0, do not use -ve index), time (saved time point)\n",
    "        baseDirName = '/home/jb739/sheffield/proj/esn_feedback/data/'+kwa['modName']+'_'+kwa['expName']; print(baseDirName)\n",
    "        dirNames = gl.glob(baseDirName+'_*'); dirNames.sort(); \n",
    "        complete = torch.load('/home/jb739/sheffield/proj/esn_feedback/data/'+kwa['modName']+'_'+kwa['expName']+'_0/complete.pt') \n",
    "        nLR = complete.shape[0]\n",
    "        dwEdges = torch.logspace(-10,-3,51) # Edges used to build histogram\n",
    "        histogram = [] # init histograms\n",
    "        fWeights = []  # init count for number of changing weights\n",
    "        dwMode = [] # Init modal DW as a function of time\n",
    "        for j, dirName in enumerate(dirNames): # Loop over learning rates\n",
    "            runs = complete[j,:]>0         # Boolean vector of which runs completed\n",
    "            nRuns= np.sum(runs.long().numpy())      # Number of completed runs\n",
    "            if nRuns>0:  # If there are any runs, do:    \n",
    "                histogram.append(np.zeros((50))) # Init storage for dw histograms\n",
    "                dwMode.append(np.ones((25))) # Init storage for dwMode\n",
    "                fileNames = gl.glob(dirName+'/dw*'); fileNames.sort() # Get run filenames\n",
    "                for k, fileName in enumerate(fileNames): # for all other completed runs\n",
    "                    if complete[j,k]>0:\n",
    "                        h = torch.load(fileName)[kwa['layer']]\n",
    "                        histogram[j] += h[:,kwa['time']]\n",
    "                        dwMode[j] = np.multiply(dwMode[j],dwEdges[np.argmax(h, axis=0)])\n",
    "                histogram[j] /= nRuns # Normalise by number of successful runs\n",
    "                dwMode[j] = np.power(dwMode[j], float(1/nRuns)) # Geometric mean of learning rates\n",
    "                fWeights.append(histogram[j].sum()/(par.Ns[kwa['layer']]*par.Ns[kwa['layer']+1])) # Fraction of weights that change\n",
    "            else:\n",
    "                # if no completed runs, append empty arrays\n",
    "                histogram.append([])\n",
    "                fWeights.append([])\n",
    "                dwMode.append([])\n",
    "        \n",
    "        # Plot DW histograms\n",
    "        mu.setupMatplotlib()\n",
    "        fig = pl.figure(figsize=tuple(np.array((6.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        col1 = np.array(tuple(x**2 for x in (0.,1.,0.3))); col2 = np.array(tuple(x**2 for x in (0.8, 0., 1.)))\n",
    "        colShade = np.linspace(0.,1.,nLR)\n",
    "        for j, hist in enumerate(histogram):\n",
    "            if len(hist)>0 and fWeights[j]>0.25: # if there is a histogram (i.e. at least one successful run)\n",
    "                col = tuple(np.sqrt(colShade[j]**2 * col2 + colShade[nLR-1-j]**2 * col1)) # set colour for this learning rate\n",
    "                pl.plot(dwEdges[:50],hist / hist.sum(), linewidth=1.0, color=col) # plot histogram\n",
    "                print(hist.sum())\n",
    "            else:\n",
    "                print([])\n",
    "        ax.set_ylim(ymin=0, ymax=0.2)\n",
    "        pl.xscale('log')\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'/dwHistogram_'+kwa['modName']+'.svg', format=\"svg\")\n",
    "        \n",
    "        # Plot number of changing weights\n",
    "        fig = pl.figure(figsize=tuple(np.array((2.,1.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        for j, frac in enumerate(fWeights):\n",
    "            if fWeights[j]>0.25:\n",
    "                col = tuple(np.sqrt(colShade[j]**2 * col2 + colShade[nLR-1-j]**2 * col1)) # set colour for this learning rate\n",
    "                pl.scatter(j, frac, s=3, color=col)\n",
    "        ax.xaxis.set_ticks([]); ax.yaxis.set_ticks((0,1))\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'/dwCount_inset_'+kwa['modName']+'.svg', format=\"svg\")\n",
    "\n",
    "        # Plot evolution of modal DW\n",
    "        fig = pl.figure(figsize=tuple(np.array((6.,4.))/2.54)); ax = pl.axes()\n",
    "        ax.spines[['top','right']].set_visible(False)\n",
    "        for j, mode in enumerate(dwMode):\n",
    "            if len(mode)>0:\n",
    "                col = tuple(np.sqrt(colShade[j]**2 * col2 + colShade[nLR-1-j]**2 * col1)) # set colour for this learning rate\n",
    "                pl.plot(np.linspace(0,par.nEpochs,25), mode, linewidth=1.0, color=col)\n",
    "        pl.yscale('log'); ax.yaxis.set_ticks([1e-7,1e-5,1e-3]); ax.yaxis.set_ticklabels(['$10^{-7}$','$10^{-5}$','$10^{-3}$']); ax.xaxis.set_ticks([0,5000]); ax.set_ylim(ymin=1e-7, ymax=dwEdges[-1])\n",
    "        # ax.get_yaxis().set_major_formatter(mpl.ticker.ScalarFormatter())\n",
    "        if kwa['saveFlag']:\n",
    "            mu.checkMakeDir(kwa['figDir'])\n",
    "            pl.savefig(kwa['figDir']+'/dwModeEvo_'+kwa['modName']+'.svg', format=\"svg\")\n",
    "      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select and run analyses\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training phase 1 accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m acc \u001b[39m=\u001b[39m esn_feedback_ana(key,modName\u001b[39m=\u001b[39mmodel,expName\u001b[39m=\u001b[39mexperiment,dataName\u001b[39m=\u001b[39mdataName)\n\u001b[1;32m      5\u001b[0m key \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mplotAcc\u001b[39m\u001b[39m'\u001b[39m; saveFlag \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m; \n\u001b[0;32m----> 6\u001b[0m esn_feedback_ana(key,acc\u001b[39m=\u001b[39;49macc,saveFlag\u001b[39m=\u001b[39;49msaveFlag, figDir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./figs/swLR/\u001b[39;49m\u001b[39m'\u001b[39;49m, figName\u001b[39m=\u001b[39;49mdataName\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mmodel)\n\u001b[1;32m      8\u001b[0m \u001b[39m# To estimate which LR to use for further analyses\u001b[39;00m\n\u001b[1;32m      9\u001b[0m mx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m; mxind \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m, in \u001b[0;36mesn_feedback_ana\u001b[0;34m(key, **kwa)\u001b[0m\n\u001b[1;32m     25\u001b[0m mu\u001b[39m.\u001b[39msetupMatplotlib()\n\u001b[1;32m     26\u001b[0m acc \u001b[39m=\u001b[39m kwa[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 27\u001b[0m nEpochs \u001b[39m=\u001b[39m acc[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     28\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(acc)\n\u001b[1;32m     29\u001b[0m col1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mtuple\u001b[39m(x\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m (\u001b[39m0.\u001b[39m,\u001b[39m1.\u001b[39m,\u001b[39m0.3\u001b[39m))); col2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mtuple\u001b[39m(x\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m (\u001b[39m0.8\u001b[39m, \u001b[39m0.\u001b[39m, \u001b[39m1.\u001b[39m)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model = 'out2FB2'\n",
    "experiment = 'swLR'\n",
    "key = 'loadData'; dataName = 'accValTa'\n",
    "acc = esn_feedback_ana(key,modName=model,expName=experiment,dataName=dataName)\n",
    "key = 'plotAcc'; saveFlag = True; \n",
    "esn_feedback_ana(key,acc=acc,saveFlag=saveFlag, figDir='./figs/swLR/', figName=dataName+'_'+model)\n",
    "\n",
    "# To estimate which LR to use for further analyses\n",
    "mx = 0; mxind = 0\n",
    "for i in range(len(acc)):\n",
    "    if np.size(acc[i])>0:\n",
    "        mn = np.mean(np.mean(acc[i][-100:,:], axis=0))\n",
    "        print(f'{i}: {mn}')\n",
    "        if mn>mx:\n",
    "            mx = mn; mxind = i\n",
    "    else:\n",
    "        print('None')\n",
    "print(f'Max is LR-index {mxind}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot transfer learning accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jb739/sheffield/proj/esn_feedback/data/out2proFB2_swLR\n",
      "/home/jb739/sheffield/proj/esn_feedback/data/out2proFB2_swLR/out_accValTa_11113.pt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jb739/sheffield/proj/esn_feedback/data/out2proFB2_swLR/out_accValTa_11113.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(baseDirName)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(baseDirName\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mdataName\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mseed\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(baseDirName\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mdataName\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mseed\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.pt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/apps/anaconda3/envs/venv/lib/python3.8/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/apps/anaconda3/envs/venv/lib/python3.8/site-packages/torch/serialization.py:231\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 231\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    232\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/apps/anaconda3/envs/venv/lib/python3.8/site-packages/torch/serialization.py:212\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 212\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jb739/sheffield/proj/esn_feedback/data/out2proFB2_swLR/out_accValTa_11113.pt'"
     ]
    }
   ],
   "source": [
    "modName = 'out2proFB2'\n",
    "expName = 'swLR'\n",
    "dataName = 'out_accValTa'\n",
    "seed='11113'\n",
    "baseDirName = '/home/jb739/sheffield/proj/esn_feedback/data/'+modName+'_'+expName\n",
    "print(baseDirName)\n",
    "print(baseDirName+'/'+dataName+'_'+seed+'.pt')\n",
    "a = torch.load(baseDirName+'/'+dataName+'_'+seed+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.5016799862384796\n",
      "1: 0.4603999866843223\n",
      "2: 0.5523599879741669\n",
      "3: 0.6445599851608277\n",
      "4: 0.7021199811697005\n",
      "Max is LR-index 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 236.22x157.48 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = 'out2FB0'\n",
    "experiment = 'swLR'\n",
    "key = 'loadData'; dataName = 'out_accValTa'\n",
    "# load accuracies (nested lists, acc[#learning rates][#runs per LR][# transfer learning instances])\n",
    "acc = esn_feedback_ana(key,modName=model,expName=experiment,dataName=dataName)\n",
    "accpl = []\n",
    "for j in range(len(acc)):\n",
    "    accpl.append([])\n",
    "    accpl[j] = np.zeros((acc[j][0][0].shape[0],len(acc[j])))\n",
    "    for k in range(len(acc[j])):\n",
    "        accpl[j][:,k] = acc[j][k][0]\n",
    "key = 'plotAcc'; saveFlag = False; \n",
    "esn_feedback_ana(key,acc=accpl,saveFlag=saveFlag, figDir='./figs/swLR/', figName=dataName+'_'+model)\n",
    "\n",
    "# To estimate which LR to use for further analyses\n",
    "mx = 0; mxind = 0\n",
    "for i in range(len(accpl)):\n",
    "    if np.size(accpl[i])>0:\n",
    "        mn = np.mean(np.mean(accpl[i][-100:,:], axis=0))\n",
    "        print(f'{i}: {mn}')\n",
    "        if mn>mx:\n",
    "            mx = mn; mxind = i\n",
    "    else:\n",
    "        print('None')\n",
    "print(f'Max is LR-index {mxind}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform PCA and clustering analyses on final hidden layer responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[0].shape\n",
    "fig = pl.figure(figsize=tuple(np.array((8.,8.))/2.54)); ax = pl.axes()\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "pl.plot(r[0][0,21,:,:].transpose())\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot response examples\n",
    "saveFlag=True; LR_index = 4; model = 'proFB2'; layer=2\n",
    "# Load data\n",
    "experiment = 'swLR'; key = 'loadResp'; dataName = 'respSave11113'\n",
    "r = esn_feedback_ana(key,modName=model,expName=experiment,dataName=dataName,selectLR=LR_index,maxNSeeds=1,layer=layer)\n",
    "# Compute principle components\n",
    "key = 'computePCA'\n",
    "p, *pca = esn_feedback_ana(key,data=r[0])\n",
    "# Plot PCs\n",
    "key = 'plotPCA'; figSuffix=model+'_LR'+str(LR_index)+'_'+'layer'+str(layer)+'_'+dataName[-5:]\n",
    "esn_feedback_ana(key,data=r[0], pca=pca[0], pc=p, saveTime=-1, saveFlag=saveFlag, figDir='./figs/swLR/', figSuffix=figSuffix)\n",
    "# Compute Clustering Index\n",
    "key = 'clusterIndex'\n",
    "SI = esn_feedback_ana(key,data=r[0])\n",
    "# Plot cluster indeces\n",
    "key = 'plotClusterIndex'; figDir = './figs/swLR/'\n",
    "esn_feedback_ana(key, ci=SI, figDir=figDir, figSuffix=figSuffix, saveFlag=saveFlag)\n",
    "# Plot mean SI across runs for all models\n",
    "key = 'plotMeanSI'; \n",
    "esn_feedback_ana(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot results summary for all models\n",
    "key = 'allSI'; layer = 1; prefix='proFB'\n",
    "si = esn_feedback_ana(key, prefix=prefix, lr_index=4, layer=layer)\n",
    "key = 'plotAllSI'; figDir='./figs/swLR'\n",
    "esn_feedback_ana(key, si=si, figDir=figDir, layer=layer, prefix=prefix, saveFlag=True)\n",
    "print(si)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot feedback weight evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=torch.load('/home/jb739/sheffield/proj/esn_feedback/data/metFB3_swLR_4/weightSave11117.pt')\n",
    "fig = pl.figure(figsize=tuple(np.array((20.,5.))/2.54)); ax = pl.axes()\n",
    "ax.spines[['top','right']].set_visible(False)\n",
    "for j in range(0,1000,100):\n",
    "    pl.plot(np.linspace(1,5000,26),weights[::2,j,:].transpose(), linewidth=0.5)\n",
    "ax.xaxis.set_ticks((0,5000)); ax.yaxis.set_ticks((-.05,0,.05)); ax.set_ylim(-.5,.5)\n",
    "print(weights[0,0,:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot evolution of mean weight changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFlag = True\n",
    "key = 'plotDW'; model = 'FB2'; experiment = 'swLR'\n",
    "esn_feedback_ana(key, saveFlag=saveFlag, modName=model, expName=experiment, figDir='./figs/swLR/', layer=1, time=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
